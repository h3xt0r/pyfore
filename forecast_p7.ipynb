{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "713574fc-e56c-4d7e-9651-9343153fbb44",
   "metadata": {},
   "source": [
    "### check versions of key python libraries\n",
    "#scipy \n",
    "import scipy\n",
    "print('scipy: %s' % scipy.__version__)\n",
    "#numpy\n",
    "import numpy\n",
    "print('numpy: %s' % numpy.__version__)\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: %s' % matplotlib.__version__)\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: %s' % pandas.__version__)\n",
    "# statsmodels\n",
    "import statsmodels\n",
    "print('statsmodels: %s' % statsmodels.__version__)\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: %s' % sklearn.__version__)\n",
    "print (\"\\n hola\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe60ca-47aa-4bd1-8386-986c4f590f76",
   "metadata": {},
   "source": [
    "# Vamos a cargar un data set de: \n",
    "\n",
    "https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-total-female-births.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43846a59-432c-4af1-b07f-2f3a880de399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Date\n",
      "1959-01-01    35\n",
      "1959-01-02    32\n",
      "1959-01-03    30\n",
      "1959-01-04    31\n",
      "1959-01-05    44\n",
      "Name: Births, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load dataset using read_csv()\n",
    "from pandas import read_csv\n",
    "series = read_csv('daily-total-female-births.csv', header=0, index_col=0, parse_dates=True,\n",
    "squeeze=True)\n",
    "print(type(series))\n",
    "print(series.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae3abbf-a5a8-4f3d-90a2-d906321f6928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be2d973c-aa54-4a7b-94e9-657eca70895d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "1959-01-01    35\n",
      "1959-01-02    32\n",
      "1959-01-03    30\n",
      "1959-01-04    31\n",
      "1959-01-05    44\n",
      "1959-01-06    29\n",
      "1959-01-07    45\n",
      "1959-01-08    43\n",
      "1959-01-09    38\n",
      "1959-01-10    27\n",
      "Name: Births, dtype: int64\n",
      "Date\n",
      "1959-12-22    39\n",
      "1959-12-23    40\n",
      "1959-12-24    38\n",
      "1959-12-25    44\n",
      "1959-12-26    34\n",
      "1959-12-27    37\n",
      "1959-12-28    52\n",
      "1959-12-29    48\n",
      "1959-12-30    55\n",
      "1959-12-31    50\n",
      "Name: Births, dtype: int64\n",
      "365\n",
      "Date\n",
      "1959-01-01    35\n",
      "1959-01-02    32\n",
      "1959-01-03    30\n",
      "1959-01-04    31\n",
      "1959-01-05    44\n",
      "1959-01-06    29\n",
      "1959-01-07    45\n",
      "1959-01-08    43\n",
      "1959-01-09    38\n",
      "1959-01-10    27\n",
      "1959-01-11    38\n",
      "1959-01-12    33\n",
      "1959-01-13    55\n",
      "1959-01-14    47\n",
      "1959-01-15    45\n",
      "1959-01-16    37\n",
      "1959-01-17    50\n",
      "1959-01-18    43\n",
      "1959-01-19    41\n",
      "1959-01-20    52\n",
      "1959-01-21    34\n",
      "1959-01-22    53\n",
      "1959-01-23    39\n",
      "1959-01-24    32\n",
      "1959-01-25    37\n",
      "1959-01-26    43\n",
      "1959-01-27    39\n",
      "1959-01-28    35\n",
      "1959-01-29    44\n",
      "1959-01-30    38\n",
      "1959-01-31    24\n",
      "Name: Births, dtype: int64\n",
      "Caracteristicas de la serie\n",
      "count    365.000000\n",
      "mean      41.980822\n",
      "std        7.348257\n",
      "min       23.000000\n",
      "25%       37.000000\n",
      "50%       42.000000\n",
      "75%       46.000000\n",
      "max       73.000000\n",
      "Name: Births, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(series.head(10)) #Primeros 10 datos\n",
    "# You can also use the tail() function to get the last n records of the dataset.\n",
    "print(series.tail(10)) #Ultimos 10 datos\n",
    "print(series.size) #total de datos\n",
    "print(series['1959-01']) #Imprimimos los datos para enero\n",
    "#vamos a ver las características de la serie:\n",
    "print(\"Caracteristicas de la serie\")\n",
    "print(series.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d93949-dd3c-4fc6-a2f1-42a44409d569",
   "metadata": {},
   "source": [
    "# 5.4 Date Time Feature\n",
    "\n",
    "https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f91b69d2-4768-4034-9629-1aaacfd1d7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series type: <class 'pandas.core.series.Series'>\n",
      "Series tail (3):\n",
      "Date\n",
      "1990-12-29    13.5\n",
      "1990-12-30    15.7\n",
      "1990-12-31    13.0\n",
      "Name: Temp, dtype: float64\n",
      "   year  month  day  temperature\n",
      "0  1981      1    1         20.7\n",
      "1  1981      1    2         17.9\n",
      "2  1981      1    3         18.8\n",
      "3  1981      1    4         14.6\n",
      "4  1981      1    5         15.8\n"
     ]
    }
   ],
   "source": [
    "# create date time features of a dataset\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "#read_csv tambien nos regresa un data frame\n",
    "series = read_csv('daily-min-temperatures.csv', header=0, \n",
    "                  index_col=0, parse_dates=True, squeeze=True)\n",
    "print(f\"series type: {type(series)}\")\n",
    "print(\"Series tail (3):\")\n",
    "print(series.tail(3))\n",
    "### Utilizando el DataFrame de pandas separamos los elementos de fecha.\n",
    "dataframe = DataFrame()\n",
    "dataframe['year'] = [series.index[i].year for i in range(len(series))]\n",
    "dataframe['month'] = [series.index[i].month for i in range(len(series))]\n",
    "dataframe['day'] = [series.index[i].day for i in range(len(series))]\n",
    "dataframe['temperature'] = [series[i] for i in range(len(series))]\n",
    "print(dataframe.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b438ea17-6600-4cca-bd33-07214a180cc1",
   "metadata": {},
   "source": [
    "Using just the month and day information alone to predict temperature is not sophisticated and will likely result in a poor model. Nevertheless, this information coupled with additional engineered features may ultimately result in a better model. You may enumerate all the properties of a time-stamp and consider what might be useful for your problem, such as:\n",
    "\n",
    "* Minutes elapsed for the day.\n",
    "* Hour of day.\n",
    "* Business hours or not.\n",
    "* Weekend or not.\n",
    "* Season of the year.\n",
    "* Business quarter of the year.\n",
    "* Daylight savings or not.\n",
    "* Public holiday or not.\n",
    "* Leap year or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c88d22-78ec-4bb1-9a6d-89471182bcee",
   "metadata": {},
   "source": [
    "Date-time based features are a good start, but it is often a lot more useful to\n",
    "include the values at previous time steps. These are called lagged values and we will look at\n",
    "adding these features in the next section.\n",
    "\n",
    "## 5.5 Lag Features\n",
    "\n",
    "Lag features are the classical way that time series forecasting problems are transformed into supervised learning problems. The simplest approach is to predict the value at the next time (t+1) given the value at the current time (t). The supervised learning problem with shifted values looks as follows:\n",
    "~~~\n",
    "Value(t), Value(t+1)\n",
    "Value(t), Value(t+1)\n",
    "Value(t), Value(t+1)\n",
    "~~~\n",
    "\n",
    "The Pandas library provides the shift() function1 to help create these shifted or lag features from a time series dataset. Shifting the dataset by 1 creates the t column, adding a NaN (unknown) value for the first row. The time series dataset without a shift represents the t+1. \n",
    "\n",
    "Let’s make this concrete with an example. The first 3 values of the temperature dataset are 20.7, 17.9, and 18.8. The shifted and unshifted lists of temperatures for the first 3 observations are therefore:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d5b8a6a-ca37-4957-b158-aba767786326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      t   t+1\n",
      "0   NaN  20.7\n",
      "1  20.7  17.9\n",
      "2  17.9  18.8\n",
      "3  18.8  14.6\n",
      "4  14.6  15.8\n"
     ]
    }
   ],
   "source": [
    "from pandas import concat\n",
    "\n",
    "temps = DataFrame(series.values)\n",
    "dataframe = concat([temps.shift(1), temps], axis=1)\n",
    "dataframe.columns = ['t', 't+1']\n",
    "print(dataframe.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f4d29c-d16e-454a-96b4-96fa0c55deba",
   "metadata": {},
   "source": [
    "You can see that we would have to discard the first row to use the dataset to train a supervised learning model, as it does not contain enough data to work with. The addition of lag features is called the sliding window method, in this case with a window width of 1. It is as though we are sliding our focus along the time series for each observation with an interest in only what is within the window width. \n",
    "\n",
    "We can expand the window width and include more lagged features. For example, below is the above case modified to include the last 3 observed values to predict the value at the next time step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a0ddb2d-aa64-4b5a-b2af-e8442648ecc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head:\n",
      "    t-2   t-1     t   t+1\n",
      "0   NaN   NaN   NaN  20.7\n",
      "1   NaN   NaN  20.7  17.9\n",
      "2   NaN  20.7  17.9  18.8\n",
      "3  20.7  17.9  18.8  14.6\n",
      "4  17.9  18.8  14.6  15.8\n",
      "tail:\n",
      "       t-2   t-1     t   t+1\n",
      "3645  10.0  12.9  14.6  14.0\n",
      "3646  12.9  14.6  14.0  13.6\n",
      "3647  14.6  14.0  13.6  13.5\n",
      "3648  14.0  13.6  13.5  15.7\n",
      "3649  13.6  13.5  15.7  13.0\n"
     ]
    }
   ],
   "source": [
    "df2 = concat([temps.shift(3), temps.shift(2), temps.shift(1), temps], axis=1)\n",
    "df2.columns = ['t-2', 't-1', 't', 't+1']\n",
    "print(\"head:\")\n",
    "print(df2.head(5))\n",
    "print(\"tail:\")\n",
    "print(df2.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f0d561-c397-4435-8be0-89875b7451c7",
   "metadata": {},
   "source": [
    "Again, you can see that we must discard the first few rows that do not have enough data to train a supervised model. A difficulty with the sliding window approach is how large to make the window for your problem. Perhaps a good starting point is to perform a sensitivity analysis and try a suite of different window widths to in turn create a suite of different views of your dataset and see which results in better performing models. There will be a point of diminishing returns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962f7842-ef16-41c8-b81a-721b85645b49",
   "metadata": {},
   "source": [
    "## 5.6 Rolling Window Statistics p31\n",
    "A step beyond adding raw lagged values is to add a summary of the values at previous time steps. We can calculate summary statistics across the values in the sliding window and include these as features in our dataset. Perhaps the most useful is the mean of the previous few values, also called the rolling mean. We can calculate the mean of the current and previous values and use that to predict the next value. For the temperature data, we would have to wait 3 time steps before we had 2 values to take the average of before we could use that value to predict a 3rd value. For example:\n",
    "\n",
    "~~~\n",
    "mean(t-1, t), t+1\n",
    "mean(20.7, 17.9), 18.8\n",
    "19.3, 18.8\n",
    "~~~\n",
    "\n",
    "Pandas provides a rolling() function3 that creates a new data structure with the window of values at each time step. We can then perform statistical functions on the window of values collected for each time step, such as calculating the mean. First, the series must be shifted.\n",
    "\n",
    "Then the rolling dataset can be created and the mean values calculated on each window of two values. Here are the values in the first three rolling windows:\n",
    "\n",
    "~~~\n",
    "#,  Window Values\n",
    "1,  NaN\n",
    "2,  NaN, 20.7\n",
    "3, 20.7, 17.9\n",
    "~~~\n",
    "This suggests that we will not have usable data until the 3rd row. Finally, as in the previous section, we can use the concat() function to construct a new dataset with just our new columns. \n",
    "\n",
    "The example below demonstrates how to do this with Pandas with a window size of 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4fdcd13-46db-43f9-ba13-53adf7860e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean(t-1,t)   t+1\n",
      "0          NaN  20.7\n",
      "1          NaN  17.9\n",
      "2        19.30  18.8\n",
      "3        18.35  14.6\n",
      "4        16.70  15.8\n"
     ]
    }
   ],
   "source": [
    "shifted = temps.shift(1)\n",
    "window = shifted.rolling(window=2)\n",
    "means = window.mean()\n",
    "dataframe = concat([means, temps], axis=1)\n",
    "dataframe.columns = ['mean(t-1,t)', 't+1']\n",
    "print(dataframe.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9acc51c-b780-456f-90f0-e1daeb33237b",
   "metadata": {},
   "source": [
    "Running the example prints the first 5 rows of the new dataset. We can see that the first two rows are not useful.\n",
    "\n",
    "* The first NaN was created by the shift of the series.\n",
    "* The second because NaN cannot be used to calculate a mean value.\n",
    "* Finally, the third row shows the expected value of 19.30 (the mean of 20.7 and 17.9) used to predict the 3rd value in the series of 18.8.\n",
    "\n",
    "There are more statistics we can calculate and even different mathematical ways of calculating the definition of the window. Below is another example that shows a window width of 3 and a dataset comprised of more summary statistics, specifically the minimum, mean, and maximum value in the window.\n",
    "\n",
    "You can see in the code that we are explicitly specifying the sliding window width as a named variable. This allows us to use it both in calculating the correct shift of the series and in specifying the width of the window to the rolling() function. \n",
    "\n",
    "In this case, the window width of 3 means we must shift the series forward by 2 time steps. This makes the first two rows NaN. Next, we need to calculate the window statistics with 3 values per window. It takes 3 rows before we even have enough data from the series in the window to start calculating statistics. The values in the first 5 windows are as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "794eaf6d-4d9a-4cc8-9dca-8175a139414c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    min       mean   max   t+1\n",
      "0   NaN        NaN   NaN  20.7\n",
      "1   NaN        NaN   NaN  17.9\n",
      "2   NaN        NaN   NaN  18.8\n",
      "3   NaN        NaN   NaN  14.6\n",
      "4  17.9  19.133333  20.7  15.8\n",
      "5  14.6  17.100000  18.8  15.8\n",
      "6  14.6  16.400000  18.8  15.8\n",
      "7  14.6  15.400000  15.8  17.4\n",
      "8  15.8  15.800000  15.8  21.8\n",
      "9  15.8  16.333333  17.4  20.0\n"
     ]
    }
   ],
   "source": [
    "width = 3\n",
    "shifted = temps.shift(width - 1)\n",
    "window = shifted.rolling(window=width)\n",
    "dataframe = concat([window.min(), window.mean(), window.max(), temps], axis=1)\n",
    "dataframe.columns = ['min', 'mean', 'max', 't+1']\n",
    "print(dataframe.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
